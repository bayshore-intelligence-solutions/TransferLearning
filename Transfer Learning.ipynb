{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"\n",
    "import numpy as np\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Internal Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](vgg16_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16    # VGG16 is already prebuild in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained VGG16 model\n",
    "# It downloads the model if it is not downloaded\n",
    "vgg_model = VGG16(weights='imagenet', include_top=True)\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "X_val = np.load('X_val.npy')\n",
    "\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "y_val = np.load('y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(units=n_classes, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting the output with VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp = vgg_model.input\n",
    "out = output(vgg_model.layers[-2].output)\n",
    "final_model = Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fa4c80f8490>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze the VGG Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in final_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in final_model.layers[-1:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 97)                397409    \n",
      "=================================================================\n",
      "Total params: 134,657,953\n",
      "Trainable params: 397,409\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam',\n",
    "                   metrics=['accuracy'])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.\n",
    "X_val = X_val.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 4346 samples, validate on 931 samples\n",
      "Epoch 1/10\n",
      "4346/4346 [==============================] - 21s 5ms/step - loss: 4.1645 - acc: 0.1546 - val_loss: 3.1307 - val_acc: 0.3437\n",
      "Epoch 2/10\n",
      "4346/4346 [==============================] - 12s 3ms/step - loss: 2.5984 - acc: 0.4370 - val_loss: 2.3337 - val_acc: 0.4801\n",
      "Epoch 3/10\n",
      "4346/4346 [==============================] - 12s 3ms/step - loss: 1.9799 - acc: 0.5591 - val_loss: 1.9301 - val_acc: 0.5489\n",
      "Epoch 4/10\n",
      "4346/4346 [==============================] - 12s 3ms/step - loss: 1.6272 - acc: 0.6404 - val_loss: 1.6821 - val_acc: 0.6337\n",
      "Epoch 5/10\n",
      "4346/4346 [==============================] - 12s 3ms/step - loss: 1.4024 - acc: 0.6815 - val_loss: 1.5540 - val_acc: 0.6412\n",
      "Epoch 6/10\n",
      "4346/4346 [==============================] - 12s 3ms/step - loss: 1.2648 - acc: 0.7181 - val_loss: 1.4470 - val_acc: 0.6681\n",
      "Epoch 7/10\n",
      "4346/4346 [==============================] - 12s 3ms/step - loss: 1.1328 - acc: 0.7356 - val_loss: 1.3555 - val_acc: 0.6563\n",
      "Epoch 8/10\n",
      "4346/4346 [==============================] - 12s 3ms/step - loss: 1.0482 - acc: 0.7607 - val_loss: 1.3205 - val_acc: 0.6606\n",
      "Epoch 9/10\n",
      "4346/4346 [==============================] - 12s 3ms/step - loss: 0.9502 - acc: 0.7809 - val_loss: 1.2633 - val_acc: 0.6874\n",
      "Epoch 10/10\n",
      "4346/4346 [==============================] - 12s 3ms/step - loss: 0.8924 - acc: 0.7954 - val_loss: 1.1983 - val_acc: 0.6960\n"
     ]
    }
   ],
   "source": [
    "history = final_model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is clearly overfitting. But in that same 10 epochs, the validation accuracy is almost **69%** which is far better than the previous model. But the training accuracy is around **79%**. This clearly means the model is overfitting. So let's add some droupout between the **Fully Connected Dense** layers and train them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First clear the GPU memory (Use only if you use GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=True)\n",
    "fc1 = vgg_model.layers[-3]\n",
    "fc2 = vgg_model.layers[-2]\n",
    "output = Dense(units=n_classes, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout1 = Dropout(0.8)\n",
    "dropout2 = Dropout(0.7)\n",
    "output = Dense(units=n_classes, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "x = dropout1(fc1.output)\n",
    "x = fc2(x)\n",
    "x = dropout2(x)\n",
    "output = output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antpc/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "droput_model = Model(input=vgg_model.input, output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 97)                397409    \n",
      "=================================================================\n",
      "Total params: 134,657,953\n",
      "Trainable params: 134,657,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "droput_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze the Conv units in VGG Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f0b385d9790>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0ac5c33b90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0ac5bc3310>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f0ac4d80dd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0ac4d80d90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0a8179da10>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f0a81765dd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0a81765b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0a81706650>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0a8171a450>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f0a816d1310>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0a816d1950>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0a816dead0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0a8167df90>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f0a8162da10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0a8162d710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0a81667a10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0a815f4f50>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f0a81625650>,\n",
       " <keras.layers.core.Flatten at 0x7f0a81625490>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droput_model.layers[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in droput_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in droput_model.layers[-5:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "droput_model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/antpc/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 4346 samples, validate on 931 samples\n",
      "Epoch 1/100\n",
      "4346/4346 [==============================] - 25s 6ms/step - loss: 5.3268 - acc: 0.0161 - val_loss: 4.5675 - val_acc: 0.0462\n",
      "Epoch 2/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 4.6275 - acc: 0.0249 - val_loss: 4.5397 - val_acc: 0.0322\n",
      "Epoch 3/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 4.5436 - acc: 0.0460 - val_loss: 4.4454 - val_acc: 0.0430\n",
      "Epoch 4/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 4.4747 - acc: 0.0529 - val_loss: 4.2799 - val_acc: 0.0827\n",
      "Epoch 5/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 4.4021 - acc: 0.0637 - val_loss: 4.1793 - val_acc: 0.0816\n",
      "Epoch 6/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 4.2990 - acc: 0.0874 - val_loss: 4.0267 - val_acc: 0.1547\n",
      "Epoch 7/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 4.1930 - acc: 0.1148 - val_loss: 3.8477 - val_acc: 0.1826\n",
      "Epoch 8/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 4.0847 - acc: 0.1381 - val_loss: 3.6469 - val_acc: 0.2589\n",
      "Epoch 9/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.9730 - acc: 0.1555 - val_loss: 3.4978 - val_acc: 0.2868\n",
      "Epoch 10/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.9511 - acc: 0.1799 - val_loss: 3.4859 - val_acc: 0.2814\n",
      "Epoch 11/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.9087 - acc: 0.1960 - val_loss: 3.3412 - val_acc: 0.2932\n",
      "Epoch 12/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.8057 - acc: 0.2200 - val_loss: 3.2118 - val_acc: 0.3072\n",
      "Epoch 13/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.7201 - acc: 0.2358 - val_loss: 3.2101 - val_acc: 0.2739\n",
      "Epoch 14/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.6770 - acc: 0.2478 - val_loss: 3.2050 - val_acc: 0.2965\n",
      "Epoch 15/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.5697 - acc: 0.2529 - val_loss: 3.0915 - val_acc: 0.3340\n",
      "Epoch 16/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.4819 - acc: 0.2685 - val_loss: 3.0180 - val_acc: 0.3437\n",
      "Epoch 17/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.3556 - acc: 0.2927 - val_loss: 2.9679 - val_acc: 0.3673\n",
      "Epoch 18/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.3320 - acc: 0.2869 - val_loss: 2.9007 - val_acc: 0.3716\n",
      "Epoch 19/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.2225 - acc: 0.3099 - val_loss: 2.8746 - val_acc: 0.3695\n",
      "Epoch 20/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.1807 - acc: 0.3125 - val_loss: 2.7502 - val_acc: 0.3963\n",
      "Epoch 21/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.0987 - acc: 0.3212 - val_loss: 2.7695 - val_acc: 0.4296\n",
      "Epoch 22/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.0709 - acc: 0.3447 - val_loss: 2.7195 - val_acc: 0.3963\n",
      "Epoch 23/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.0025 - acc: 0.3449 - val_loss: 2.6457 - val_acc: 0.4049\n",
      "Epoch 24/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.0245 - acc: 0.3497 - val_loss: 2.6234 - val_acc: 0.4361\n",
      "Epoch 25/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 3.0166 - acc: 0.3495 - val_loss: 2.6327 - val_acc: 0.4060\n",
      "Epoch 26/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.9879 - acc: 0.3523 - val_loss: 2.7280 - val_acc: 0.3835\n",
      "Epoch 27/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.8637 - acc: 0.3691 - val_loss: 2.5671 - val_acc: 0.4275\n",
      "Epoch 28/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.9165 - acc: 0.3633 - val_loss: 2.5769 - val_acc: 0.4511\n",
      "Epoch 29/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.8161 - acc: 0.3771 - val_loss: 2.4556 - val_acc: 0.4758\n",
      "Epoch 30/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.8116 - acc: 0.3787 - val_loss: 2.4545 - val_acc: 0.4533\n",
      "Epoch 31/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.7316 - acc: 0.3974 - val_loss: 2.4314 - val_acc: 0.4554\n",
      "Epoch 32/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.7232 - acc: 0.4008 - val_loss: 2.3709 - val_acc: 0.4823\n",
      "Epoch 33/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.7479 - acc: 0.3990 - val_loss: 2.5100 - val_acc: 0.4501\n",
      "Epoch 34/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.7213 - acc: 0.3930 - val_loss: 2.3751 - val_acc: 0.4705\n",
      "Epoch 35/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.6726 - acc: 0.4181 - val_loss: 2.3321 - val_acc: 0.4909\n",
      "Epoch 36/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.6665 - acc: 0.4107 - val_loss: 2.3454 - val_acc: 0.4629\n",
      "Epoch 37/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.6395 - acc: 0.4119 - val_loss: 2.3028 - val_acc: 0.4769\n",
      "Epoch 38/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.5727 - acc: 0.4243 - val_loss: 2.2842 - val_acc: 0.4619\n",
      "Epoch 39/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.6772 - acc: 0.4225 - val_loss: 2.3625 - val_acc: 0.4554\n",
      "Epoch 40/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.6711 - acc: 0.4119 - val_loss: 2.3538 - val_acc: 0.4554\n",
      "Epoch 41/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.6003 - acc: 0.4379 - val_loss: 2.2091 - val_acc: 0.4705\n",
      "Epoch 42/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.5747 - acc: 0.4340 - val_loss: 2.3157 - val_acc: 0.4597\n",
      "Epoch 43/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.6248 - acc: 0.4225 - val_loss: 2.2699 - val_acc: 0.4823\n",
      "Epoch 44/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.5496 - acc: 0.4236 - val_loss: 2.2746 - val_acc: 0.4855\n",
      "Epoch 45/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.5966 - acc: 0.4406 - val_loss: 2.3267 - val_acc: 0.4296\n",
      "Epoch 46/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.5647 - acc: 0.4328 - val_loss: 2.1771 - val_acc: 0.4748\n",
      "Epoch 47/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4840 - acc: 0.4524 - val_loss: 2.1311 - val_acc: 0.5091\n",
      "Epoch 48/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4791 - acc: 0.4388 - val_loss: 2.1727 - val_acc: 0.4952\n",
      "Epoch 49/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4748 - acc: 0.4418 - val_loss: 2.1432 - val_acc: 0.4748\n",
      "Epoch 50/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.5040 - acc: 0.4512 - val_loss: 2.1733 - val_acc: 0.4726\n",
      "Epoch 51/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4746 - acc: 0.4528 - val_loss: 2.1515 - val_acc: 0.5113\n",
      "Epoch 52/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4461 - acc: 0.4556 - val_loss: 2.0445 - val_acc: 0.5317\n",
      "Epoch 53/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4067 - acc: 0.4694 - val_loss: 2.1525 - val_acc: 0.4898\n",
      "Epoch 54/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4832 - acc: 0.4577 - val_loss: 2.1865 - val_acc: 0.4941\n",
      "Epoch 55/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4775 - acc: 0.4561 - val_loss: 2.0749 - val_acc: 0.5209\n",
      "Epoch 56/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4036 - acc: 0.4685 - val_loss: 2.0724 - val_acc: 0.5102\n",
      "Epoch 57/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.5640 - acc: 0.4480 - val_loss: 2.1309 - val_acc: 0.4694\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4090 - acc: 0.4584 - val_loss: 2.1093 - val_acc: 0.4984\n",
      "Epoch 59/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.4119 - acc: 0.4781 - val_loss: 2.2185 - val_acc: 0.4758\n",
      "Epoch 60/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3932 - acc: 0.4669 - val_loss: 2.0653 - val_acc: 0.5134\n",
      "Epoch 61/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3115 - acc: 0.4814 - val_loss: 2.0484 - val_acc: 0.5081\n",
      "Epoch 62/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3447 - acc: 0.4823 - val_loss: 2.0981 - val_acc: 0.4930\n",
      "Epoch 63/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2799 - acc: 0.4867 - val_loss: 2.0002 - val_acc: 0.5145\n",
      "Epoch 64/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3745 - acc: 0.4830 - val_loss: 2.0127 - val_acc: 0.5113\n",
      "Epoch 65/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3869 - acc: 0.4756 - val_loss: 2.0803 - val_acc: 0.5081\n",
      "Epoch 66/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3026 - acc: 0.4917 - val_loss: 1.9831 - val_acc: 0.5295\n",
      "Epoch 67/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3147 - acc: 0.4922 - val_loss: 1.9699 - val_acc: 0.5285\n",
      "Epoch 68/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2438 - acc: 0.5021 - val_loss: 2.0026 - val_acc: 0.5113\n",
      "Epoch 69/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3486 - acc: 0.4850 - val_loss: 2.0229 - val_acc: 0.5102\n",
      "Epoch 70/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3493 - acc: 0.4887 - val_loss: 2.0754 - val_acc: 0.5005\n",
      "Epoch 71/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2983 - acc: 0.5000 - val_loss: 1.9017 - val_acc: 0.5231\n",
      "Epoch 72/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3107 - acc: 0.4917 - val_loss: 1.9611 - val_acc: 0.5166\n",
      "Epoch 73/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3422 - acc: 0.4979 - val_loss: 2.0359 - val_acc: 0.5166\n",
      "Epoch 74/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3268 - acc: 0.4901 - val_loss: 2.0239 - val_acc: 0.4995\n",
      "Epoch 75/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2911 - acc: 0.5053 - val_loss: 2.0211 - val_acc: 0.5124\n",
      "Epoch 76/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1880 - acc: 0.5064 - val_loss: 1.9160 - val_acc: 0.5446\n",
      "Epoch 77/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3026 - acc: 0.4970 - val_loss: 1.9451 - val_acc: 0.5263\n",
      "Epoch 78/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.3315 - acc: 0.5009 - val_loss: 2.0056 - val_acc: 0.5252\n",
      "Epoch 79/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2028 - acc: 0.5106 - val_loss: 2.0576 - val_acc: 0.5005\n",
      "Epoch 80/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2394 - acc: 0.5152 - val_loss: 1.9551 - val_acc: 0.5199\n",
      "Epoch 81/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2351 - acc: 0.5129 - val_loss: 1.9715 - val_acc: 0.5199\n",
      "Epoch 82/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1905 - acc: 0.5207 - val_loss: 1.8881 - val_acc: 0.5381\n",
      "Epoch 83/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2395 - acc: 0.5108 - val_loss: 1.9503 - val_acc: 0.5081\n",
      "Epoch 84/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2621 - acc: 0.5071 - val_loss: 1.9621 - val_acc: 0.5242\n",
      "Epoch 85/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1984 - acc: 0.5147 - val_loss: 1.8738 - val_acc: 0.5435\n",
      "Epoch 86/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1934 - acc: 0.5285 - val_loss: 1.9622 - val_acc: 0.5252\n",
      "Epoch 87/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1776 - acc: 0.5246 - val_loss: 1.8435 - val_acc: 0.5328\n",
      "Epoch 88/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2294 - acc: 0.5115 - val_loss: 2.0006 - val_acc: 0.5263\n",
      "Epoch 89/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2141 - acc: 0.5159 - val_loss: 1.8425 - val_acc: 0.5478\n",
      "Epoch 90/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2134 - acc: 0.5104 - val_loss: 1.9796 - val_acc: 0.5005\n",
      "Epoch 91/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1021 - acc: 0.5246 - val_loss: 1.9045 - val_acc: 0.5263\n",
      "Epoch 92/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2219 - acc: 0.5249 - val_loss: 1.9407 - val_acc: 0.5231\n",
      "Epoch 93/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1786 - acc: 0.5235 - val_loss: 1.8369 - val_acc: 0.5371\n",
      "Epoch 94/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1927 - acc: 0.5163 - val_loss: 1.8231 - val_acc: 0.5607\n",
      "Epoch 95/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.0880 - acc: 0.5278 - val_loss: 1.8388 - val_acc: 0.5596\n",
      "Epoch 96/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1313 - acc: 0.5237 - val_loss: 1.8669 - val_acc: 0.5371\n",
      "Epoch 97/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.0841 - acc: 0.5253 - val_loss: 1.7789 - val_acc: 0.5456\n",
      "Epoch 98/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1661 - acc: 0.5207 - val_loss: 1.9607 - val_acc: 0.5113\n",
      "Epoch 99/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.2010 - acc: 0.5283 - val_loss: 1.8405 - val_acc: 0.5317\n",
      "Epoch 100/100\n",
      "4346/4346 [==============================] - 13s 3ms/step - loss: 2.1000 - acc: 0.5391 - val_loss: 1.8401 - val_acc: 0.5338\n"
     ]
    }
   ],
   "source": [
    "history = droput_model.fit(X_train, y_train, batch_size=128, epochs=100,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932/932 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = droput_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7852234886439573"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5718884120171673"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
